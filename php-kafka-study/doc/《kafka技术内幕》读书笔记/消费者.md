### 消息生产方案
> 1. 生产者发送消息时在客户端就按照节点和partition进行分组，属于同一个目标节点的多个Partition会作为同一个请求传送到服务端，作为目标节点的服务端也可以处理来自不同生产者客户端的请求。
> 2. 网络层通讯来看：客户端和服务端都会使用队列的方式确保顺序地客户端发送请求，服务端接收请求，服务端发送响应，客户端接收响应。
> 3. 存储层来看：生产者会将消息分发到不同节点的不同Partition上，服务端的一个Partition的数据会来源于多个生产者。多个服务端节点组成的Kafka集群在物理层将消息分布在不同节点的不同Partition上，并且是以提交日志的形式追加到每个Partition中。对消息进行分区的好处是可以将大量的消息分成多批数据同时写到不同节点上，将写请求分担负载到各个节点。


### 消息系统模型
![image](https://images.weserv.nl/?url=http://img.blog.csdn.net/20160527112701511)


### 消息消费方案
1. 消息存在不同的partition的kafka集群中，消息不能重复消费原则，为了防止同一个消息被多个消费者冲突消费锁。根据系统的负载均衡算法平均一个partition指定一个消费者消费，也就是同一个partition只能是一个消费者消费。
2. 这是一种负载均衡方案均衡消费者分担消费任务，这些消费者的处理逻辑都是相同的，每个消费者处理的Partition都是不会重复的。
3. 不同消费组都会消费所有的partition消息，同一个消费组的消费者对partition是互斥的。
4. 不同消费组的不同消费者可以消费同一个topic的同一个消息，这个就是发布-订阅模式；
5. 同一个消费组消费消息就是单播队列模式；


### 消息的rebalance方案
1. 消费组线程通过Zookeeper 上注册 Watch 完成Rebalance 负载均衡算法。
2. 均衡算法：
    1. 将目标 Topic 下的所有 Partirtion 排序，存于 PT；
    2. 对某 Consumer Group 下所有 Consumer 排序，存于 CG，第 i 个 Consumer 记为 Ci
    3. N=size(PT)/size(CG)，向上取整
    4. 解除 Ci 对原来分配的 Partition 的消费权（i 从 0 开始）
    5. 将第i*N到（i+1）*N-1个 partition 分配给 Ci　　
    
3. consumer rebalance的控制策略是由每一个consumer通过Zookeeper完成的。具体的控制方式如下：
    1. 在/consumers/[consumer-group]/下注册id
    2. 设置对/consumers/[consumer-group] 的watcher
    3. 设置对／brokers/ids的watcher
    4. zk下设置watcher的路径节点更改，触发consumer rebalance

4. 在这种策略下，每一个consumer或者broker的增加或者减少都会触发consumer rebalance。因为每个consumer只负责调整自己所消费的partition，为了保证整个consumer group的一致性，所以当一个consumer触发了rebalance时，该consumer group内的其它所有consumer也应该同时触发rebalance。

5. 这种方案有两个严重问题：
    1. 羊群效应：同一个group的不同成员会因为一个成员退出只有该成员关注的topic导致这个group的所有成员触发rebalance；
    2. 脑裂：每个Consumer都是通过zk中保存的元数据来判断group中各其他成员的状态，以及broker的状态，进而分别进入各自的Rebalance，执行各自的Rebalance逻辑。那么就导致不同的Consumer在同一时刻可能连接在不同的zk服务器上，看到的元数据就可能不一样，基于不一样的元数据，执行Rebalance就会产生不一致（冲突）的Rebalance结果，Rebalance的冲突，会到导致consumer的rebalance失败。
    

### 新的rebalance方案（version>=0.9）
1. 协调者GroupCoordinator：将全部的Consumer Group分成多个子集，每个Consumer Group子集在Broker端对应一个GroupCoordinator对其进行管理；
2. **一个基于事件驱动的消费组状态机**。其分配工作被设计在消费端；
3. **消费组Group Leader**：当消费者找到管理当前Consumer Group的GroupCoordinator后就进入Join Group阶段，Consumer首先向GroupCoordinator发送JoinGroupRequest请求，其中包含了消费者的相关信息；GroupCoordinator在收到了消费者发来的JoinGroupRequest请求后，会暂存消费者的信息，待在一定时间内收集到全部消费者信息后，则将根据从所有消费者中选出1位消费者称为Group Leader，还会选取使用的分区分配策略，这些信息都将打包在JoinGroupResponse中返回给消费者。每个消费者都将受到JoinGroupResponse响应，但是只有Group Leader收到的JoinGroupResponse响应中包含了所有消费者信息。当消费者确定自己是Group Leader后，会根据消费者的信息以及选定的分区分配策略进行分区分配。这个阶段称为**Join Group阶段**
4. **Synchronize Group State阶段**：每个消费者会发送SyncGroupRequest到GroupCoordinator，但是，只有Group Leader的SyncGroupRequest请求包含了分区的分配结果，GroupCoordinator根据Group Leader的分区分配结果，形成SyncGroupResponse，并返回给所有消费者。消费者在收到SyncGroupResponse后即可获知归属自己的分区信息。


### 高级API和低级API
1. Hight Level Consumer：
    1. 高级API提供了一个从Kafka消费数据的高层抽象，消费者客户端代码不需要管理offset的提交，并且采用了消费组的自动负载均衡功能，确保消费者的增减不会影响消息的消费；
    2. 主要实现类ConsumerGroup；
    3. 通过监听器触发消费者的rebalance，管理offset
    4. 应用场景：
        1. 消息重复消费；
        2. 添加事务管理机制，保证 Exactly Once
        3. 消费指定分区或者指定分区的某些片段
```
// 订阅topic
rd_kafka_resp_err_t rd_kafka_subscribe (rd_kafka_t *rk,const rd_kafka_topic_partition_list_t *topics);

// 取消订阅
rd_kafka_resp_err_t rd_kafka_unsubscribe (rd_kafka_t *rk);

// 获取当前的订阅
rd_kafka_resp_err_t
rd_kafka_subscription (rd_kafka_t *rk,rd_kafka_topic_partition_list_t **topics);

// 消费message
rd_kafka_message_t *rd_kafka_consumer_poll (rd_kafka_t *rk, int timeout_ms);

// 关闭consumer
rd_kafka_resp_err_t rd_kafka_consumer_close (rd_kafka_t *rk);

// 分派partition,跟rd_kafka_subscribe()的区别就是assign必须有partition才生效，
// 当你知道partition的时候，最好用这个，因为kafka不用再去找了，速度最快
rd_kafka_resp_err_t rd_kafka_assign (rd_kafka_t *rk, const rd_kafka_topic_partition_list_t *partitions);

// 获取当前分派的partition
rd_kafka_resp_err_t rd_kafka_assignment (rd_kafka_t *rk, rd_kafka_topic_partition_list_t **partitions);

// 手动commit，可以同步可以异步，异步的时候要设置rd_kafka_conf_set_offset_commit_cb()
rd_kafka_resp_err_t rd_kafka_commit (rd_kafka_t *rk, const rd_kafka_topic_partition_list_t *offsets, int async);

// 手动commit
rd_kafka_resp_err_t rd_kafka_commit_message (rd_kafka_t *rk, const rd_kafka_message_t *rkmessage, int async);

// 获取当前commit的offset
rd_kafka_resp_err_t rd_kafka_committed (rd_kafka_t *rk, rd_kafka_topic_partition_list_t *partitions, int timeout_ms);

// 获取当前topic+partition的offset
rd_kafka_resp_err_t rd_kafka_position (rd_kafka_t *rk, rd_kafka_topic_partition_list_t *partitions);
```

    
2. Low Level Consumer：
    1. 低级API通常针对特殊的消费逻辑（比如客消费者只想要消费某些特定的Partition），低级API的客户端代码需要自己实现一些和Kafka服务端相关的底层逻辑，比如选择Partition的Leader，处理Leader的故障转移等。  
    2. 主要实现类SimpleConsumer
    3. 手动选举leader，拉取消息，处理broker故障


```
// 开始接收message
int rd_kafka_consume_start(rd_kafka_topic_t *rkt, int32_t partition, int64_t offset);

// 停止接收
int rd_kafka_consume_stop(rd_kafka_topic_t *rkt, int32_t partition);

// 查找现在的offset
rd_kafka_resp_err_t rd_kafka_seek (rd_kafka_topic_t *rkt, int32_t partition, int64_t offset, int timeout_ms);

// 接收一条message
rd_kafka_message_t *rd_kafka_consume(rd_kafka_topic_t *rkt, int32_t partition, int timeout_ms);

// 接收多条message
ssize_t rd_kafka_consume_batch(rd_kafka_topic_t *rkt, int32_t partition, int timeout_ms, rd_kafka_message_t **rkmessages, size_t rkmessages_size);

// 使用回调处理收到的message，速度最快
int rd_kafka_consume_callback(rd_kafka_topic_t *rkt, int32_t partition, int timeout_ms, void (*consume_cb) (rd_kafka_message_t *rkmessage, void *opaque), void *opaque);

// 手动commit
rd_kafka_resp_err_t rd_kafka_offset_store(rd_kafka_topic_t *rkt, int32_t partition, int64_t offset);
```
