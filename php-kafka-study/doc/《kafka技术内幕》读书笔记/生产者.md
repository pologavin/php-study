> 生产者客户端将消息写入消费代理broker。生产者客户端对象kafkaProducer.

1. 每条消息都会被包装成一条生产者记录（ProducerRecord),并传给生产者客户端kafkaProducer对象的send发送方法，isAsync变量记录发送消息的模式，同步或者异步，同步发送生产者发送消息必须等待服务端返回反应结果才能发送下一个消息；异步发送生产者发送消息不用关心服务器处理，可以接着发送下一条消息。还传递一个callback匿名回调类的回调方法onCompletion。


2. 发送消息send方法：
    1. 首先序列化消息的key和value为二进制流，发送到服务端，找到相应的broker后根据分区算法选择对应的分区，最后通知发送线程发送消息。

3. 消息分区：
    1. parttion()方法实现。对于没有键的消息，通过计数器自增轮询方式一次将消息分配到不同的分区上；对于有键的消息，对键值计算hash散列值 ，然后和主题的分区数进行取模得到分区编号。
    2. 主题的分区数，默认在$KAFKA_HOME/config/server.properties中通过配置项num.partitions。可以topic创建参数设置分区数
    
    ```
    // 创建设置
    ./kafka-topics.sh --create --zookeeper zookeeper01:218 --partitions 2 --topic szy
    
    // 修改
    ./kafka-topics.sh --alter --zookeeper zookeeper01:218  --partitions 3 --topic szy
    
    ```

    3. 每个patition物理上对应一个文件夹（该文件夹存储该patition的所有消息和索引文件）如下：
        
    ```
    drwxr-xr-x  6 gaojun  wheel   192B  5  9 17:20 topic_test_demo-0
    drwxr-xr-x  6 gaojun  wheel   192B  5 10 13:57 topic_test_demo-1
    
    gaojun@bogon  /var/docker/Docker-LNMP/kafka/broker01/kafka-logs-broker01/topic_test_demo-0  ll
    total 49168
    -rw-r--r--  1 gaojun  wheel    10M  5 10 14:15 00000000000000000000.index
    -rw-r--r--  1 gaojun  wheel   3.4M  5 10 14:15 00000000000000000000.log
    -rw-r--r--  1 gaojun  wheel    10M  5 10 14:15 00000000000000000000.timeindex
    ```

```
/**
 * Compute the partition for the given record.
 *
 * @param topic The topic name
 * @param key The key to partition on (or null if no key)
 * @param keyBytes serialized key to partition on (or null if no key)
 * @param value The value to partition on or null
 * @param valueBytes serialized value to partition on or null
 * @param cluster The current cluster metadata
 */
public int partition(String topic, Object key, byte[] keyBytes, Object value, byte[] valueBytes, Cluster cluster) {
    /* 从 Cluster 中获取对应的 Topic 的分区信息 */
    List<PartitionInfo> partitions = cluster.partitionsForTopic(topic);
    /* 分区数量 */
    int numPartitions = partitions.size();
    /* 没有 key 的情况 */
    if (keyBytes == null) {
        /* 递增 counter */
        int nextValue = counter.getAndIncrement();
        /* 选择 avaliablePartitions */
        List<PartitionInfo> availablePartitions = cluster.availablePartitionsForTopic(topic);
        if (availablePartitions.size() > 0) {
            int part = Utils.toPositive(nextValue) % availablePartitions.size();
            return availablePartitions.get(part).partition();
        } else {
            // no partitions are available, give a non-available partition
            return Utils.toPositive(nextValue) % numPartitions;
        }
    } else { /* 消息有可以的情况 */
        // hash the keyBytes to choose a partition
        return Utils.toPositive(Utils.murmur2(keyBytes)) % numPartitions;
    }
}
```

4. 客户端记录收集器:
    1. 生产者发送的消息先在客户端缓存到记录收集器RecordAccumulator中，等到一定时机再由发送线程sender批量写入kafka集群中。当生成一条消息，就像记录收集器追加一条消息,返回是否批记录RecordBatch是否满了，如果满了就开始发送这批消息。
    

5. 客户端消息发送线程：
    1. 记录收集器是按照分区进行分组，存放在batches集合中。发送线程sender也是根据分区进行发送消息。
    2. 两种发送方式：一种是直接分区发送，一种是分区目标节点发送。后者网络请求少。
    3. 发送过程：从记录收集器获取数据；创建生产者客户端请求produceRequest()。交给客户端网络连接对象。
    

6. 客户端网络连接对象：
> NetworkClient 管理客户端和服务端之间的网络通讯：

    1. ready():从记录收集器获取准备完毕的节点，并连接所有准备好的节点；
    2. send():为每个节点创建一个客户端请求，将请求暂存到节点对应的通道中；
    3. poll():轮训动作会真正执行网络请求。
    

7. 客户端请求对象ClientRequest和客户端响应对象ClientResponse
> 1. ClientRequet 包含客户端发送的请求RequestSend和回调处理器callback。
> 2. ClientResponse 包含客户端请求对象ClientRequest和响应结果内容ResponseBody


8. 请求过程：
    1. 发送线程创建的客户端请求对象包括请求本身和回调对象；
    2. 发送线程将客户端请求交给网络连接对象NetworkClient，并记录目标节点到客户端请求的映射关系；
    3. NetworkClient的轮询得到发送请求，将客户端请求发送到对应的服务端目标节点；
    4. 服务端处理客户端请求，将客户端响应通过服务端的请求通道返回客户端；
    5. NetworkClient的轮询得到响应结果，说明客户端收到服务端发送过来的请求处理结果；
    6. 由于客户端请求发送到不同的节点，收到的结果也来自不同的节点，客户端根据NetworkReceive的source查找客户端信息，把客户端请求作为客户端响应的成员变量；
    7. 调用ClientResponse.ClientRequest.callback.onComplete()触发回调函数；
    8. 客户端请求中的回调对象会使用客户端的响应结果，来调用生产者应用程序自定义的回调函数；
    

9. kafka通道
> socketChannel注册到选择器上返回选择键，将选择器用于构造传输层，再把传输层用于构造kafka通道，kafka通道和SocketChannel通过选择键进行了关联。kafkaChannel本质上是对原始SocketChannel的一层包装。

```
public class KafkaChannel {
Private final String id;
private final Transportlayer Transportlayer 

```


### 整体流程
![image](https://github.com/BingLau7/blog/blob/master/images/blog_42/Kafka.png?raw=true)

1. ProducerInterceptors 对消息进行拦截
2. Serializer 对消息的 key 和 value 进行序列化
3. Partitioner 为消息选择合适的 Partition
4. RecordAccumulator 收集消息，实现批量发送
5. Sender 从 RecordAccumulator 获取消息
6. 构造 ClientRequest
7. 将 ClientRequest 交给 NetworkClient，准备发送
8. NetworkClient 将请求放入 KafkaChannel 的缓存
9. 执行网络 I/O，发送请求
10. 收到响应，调用 ClientRequest 的回调函数
11. 调用 RecordBatch的回调函数，最终调用每个消息上注册的回调函数。

### Producer的功能主要由两个线程协同工作完成：
1. 主线程主要将业务数据封装成ProducerRecord对象，压入由RecordAccumulator（(消息收集器，也可以理解为主线程与 Sender 线程之间的缓冲区)）构建的数据Queue中
2. Sender线程主要从Queue中获取数据，封装成请求报文，并最终通过网络IO线程将数据发送到Kafka
3. KafkaProducer是线程安全的，多个线程间可以共享使用同一个 KafkaProucer 对象。


### KafkaProducer API
1. send() 方法：发送消息，实际是将消息放入 RecordAccumulator 暂存，等待发送
2. flush() 方法：刷新操作，等待 RecordAccumulator 中所有消息发送完成，在刷新之前就会阻塞调用的线程
3. partitionsFor() 方法：在 KafkaProducer 中维护了一个 Metadata 对象用于存储 Kafka 集群的元素局，Metadata 中的元素局会定时更新。partitionsFor() 方法负责从 Metadata 中获取指定 Topic 中的分区信息。
4. close() 方法：关闭此 Producer 对象，主要操作是设置 close 壁纸，等待 RecordAccumulator 中的消息清空，关闭 Sender 线程。


### KafkaProducer重要字段
```
/* clientId 的生成器，如果没有明确指定 client 的 id，则使用字段生成一个 ID */
private static final AtomicInteger PRODUCER_CLIENT_ID_SEQUENCE = new AtomicInteger(1);
/* 此生产者的唯一标识 */
private String clientId;
/* 分区选择器，根据一定的策略，将消息路由到合适的分区 */
private final Partitioner partitioner;
/* 消息的最大长度，这个长度包含了消息头、序列化后的 key 和序列化后的 value 的长度 */
private final int maxRequestSize;
/* 发送单个消息的缓冲区大小 */
private final long totalMemorySize;
/* 存储 Kafka 集群的元数据 */
private final Metadata metadata;
/* RecordAccumulator，用于手机并缓存消息，等待 Sender 线程发送 */
private final RecordAccumulator accumulator;
/* 发送消息的 Sender 任务，实现了 Runnable 接口，在 ioThread 线程中执行 */
private final Sender sender;
private final Metrics metrics;
/* 执行 Sender 任务发送消息的线程，称为 『Sender 线程』 */
private final Thread ioThread;
/* 压缩算法，可选项有 none、gzip、snappy、lz4.
* 这是针对 RecordAccumulator 中多条消息进行的压缩，所以消息越多，压缩效果越好 */
private final CompressionType compressionType;
/* key 的序列化器 */
private final Serializer<K> keySerializer;
/* value 的序列化器 */
private final Serializer<V> valueSerializer;
/* 配置对象，使用反射初始化 KafkaProducer 配置的相对对象 */
private final ProducerConfig producerConfig;
/* 等待更新 Kafka 集群元数据的最大时长 */
private final long maxBlockTimeMs;
/* 消息的超时时间，也就是从消息发送到收到 ACK 响应的最长时长 */
private final int requestTimeoutMs;
/* ProducerInterceptor 集合，ProducerInterceptor 可以在消息发送之前对其进行拦截或修改；
* 也可以先于用户的 Callback，对 ACK 响应进行预处理 */
private final ProducerInterceptors<K, V> interceptors;
```
