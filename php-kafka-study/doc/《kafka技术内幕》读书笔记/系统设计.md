- 流式数据平台
1. 消息系统：使用消费组（consumer group ）统一队列和发布订阅的两种消息模型。首先使用队列模型可以将处理工作平均分配给消费组中的消费者成员；使用发布订阅模式可以将消息广播给多个消费组。kafka采用多消费组结合多消费者既可以线性扩展消息的处理能力，也可以允许消息被多个消费组订阅。
2. 存储系统：消息数据需要落地持久化存储，消息队列的“发布消息”和“消费消息”做到解耦。数据写入kafka集群服务器节点时会复制同步多个节点保证数据可靠性。
3. 流处理系统：使用kafka的生产者和消费者API实现实时流式数据处理。

- 分区模型
1. kafka的集群是由多个消息代理服务器(brooker server)组成，消息是按topic进行分类每个topic下的消息根据消息key进行负载均衡算法均衡并行写入不同的broker的不同分区里（parttion）。
2. topic的分区是消息处理的并行单位，kafka以分区作为最小的粒度，将每个分区分配给消费组中不同的而且唯一的消费者，并确保一个分区只属于一个消费者，即这个消费者就是这个分区的唯一读取线程。只要分区的消息是有序的，消费者的消息顺序就可以保证顺序。
3. 每个消息对象中都有个offset偏移量，这个是消息在parttion的偏移量。可以根据偏移量快速获取消息。


- 消费模型
1. 消息系统的消费模型有两种：
    1. 推送模型（push）：由消息代理记录消费者的消费状态，消费代理在将消息推送到消费者后标记为已消费。但这种方式无法很好保证消息的处理语义，消息推送是否因为网络问题导致没有达到消费者，这个没有保证。
    2. 拉取模型：由消费者自己记录消费状态，每个消费者互相独立读取每个分区的消息，这种方式既可以保证消息正确的达到也可以保证消息可以根据偏移量来回溯消息。
    3. kafka的消费模式是采用拉取模型，服务端可以配置消息保留时长，过期后消息会被清理。
    

- 分布模型
1. 消息使用分区实现负载均衡，每个分区的消息也会同步复制到每个服务端节点broker。每个客户端的请求都会通过zookeeper做broker的均衡分发。


- 存储策略
1. 无论消息是否被消费，kafka都会保留所有消息。有两种策略可以删除旧数据：需要注意的是，因为Kafka读取特定消息的时间复杂度为O(1)，即与文件大小无关，所以这里删除过期文件与提高 Kafka 性能无关。
    1. 基于时间：log.retention.hours=168
    2. 基于大小：log.retention.bytes=1073741824

2. kafka的持久化更像redis，数据都在内存中，定期flush到硬盘上持久化存储。以保证重启时数据不丢。flush策略由log.flush.*这些properties控制。
3. 每个topic可以存储多个partition，每个partition在kafka的log目录下表现为topicname-id这样的文件夹，如mytopic-0。kafka队列中的内容会按照日志的形式持久化到硬盘上。每个日志文件称为“段”(segment)。
4. Kafka清理队列中过期message的方式实际上就是删除过期的segment，这种表现形式十分类似于日志滚动。因此，控制kafka队列中消息的保存时间的方式实际上就是日志文件定期分段，然后定期清理掉过期的段文件。
5. 与控制分段策略相关的几个properties:

```
log.roll.{hours,ms} —— 日志滚动的周期时间(小时,毫秒，log.roll.ms优先级更高)，到达指定周期时强制生成一个新的segment。
log.segment.bytes —— 每个segment的最大容量上限(默认1GB)。到达指定容量时会强制生成一个新的segment。
```
6. 与过期segment处理策略相关的几个properties：

```
cleanup.policy={compact,delete} —— 过期segment处理算法，默认delete。
log.retention.{hours,minutes,ms} —— 日志保留时间(小时，分钟，毫秒。优先级依次升高)，超出保留时间的日志执行cleanup.policy定义的操作
log.segment.delete.delay.ms —— 删除日志文件前的保留一段时间。默认60000。
log.retention.check.interval.ms —— log checker的检测是否需要删除文件的周期。默认300000。
```
7. 存储文件
    1. {log.dirs}/{TOPIC-NAME-PARTITION-ID}/*.log
        1. 存储消息内容
        2. 使用kafka工具查看：
        
        ```
        ./kafka-run-class.sh kafka.tools.DumpLogSegments --files /kafka/kafka-logs-broker01/topic_test_demo-0/00000000000000000000.index
        ```
        
        ```
        Dumping /kafka/kafka-logs-broker01/topic_test_demo-0/00000000000000000000.log
        Starting offset: 0
        offset: 0 position: 0 CreateTime: 1557393691677 isvalid: true keysize: 10 valuesize: 8 magic: 2 compresscodec: NONE producerId: -1 producerEpoch: -1 sequence: 0 isTransactional: false headerKeys: [] key: group_demo payload: {"id":0}
        offset: 1 position: 86 CreateTime: 1557393691717 isvalid: true keysize: 10 valuesize: 8 magic: 2 compresscodec: NONE producerId: -1 producerEpoch: -1 sequence: 0 isTransactional: false headerKeys: [] key: group_demo payload: {"id":1}
        offset: 2 position: 172 CreateTime: 1557393692735 isvalid: true keysize: 10 valuesize: 8 magic: 2 compresscodec: NONE producerId: -1 producerEpoch: -1 sequence: 0 isTransactional: false headerKeys: [] key: group_demo payload: {"id":2}
        offset: 3 position: 258 CreateTime: 1557393693752 isvalid: true keysize: 10 valuesize: 8 magic: 2 compresscodec: NONE producerId: -1 producerEpoch: -1 sequence: 0 isTransactional: false headerKeys: [] key: group_demo payload: {"id":3}
        offset: 4 position: 344 CreateTime: 1557393694763 isvalid: true keysize: 10 valuesize: 8 magic: 2 compresscodec: NONE producerId: -1 producerEpoch: -1 sequence: 0 isTransactional: false headerKeys: [] key: group_demo payload: {"id":4}
        offset: 5 position: 430 CreateTime: 1557393695776 isvalid: true keysize: 10 valuesize: 8 magic: 2 compresscodec: NONE producerId: -1 
        ......
        
        ```

    2. {log.dirs}/{TOPIC-NAME}/*.index
        1. 存储元数据,索引信息
        2. 使用kafka工具查看：
            
        ```
        Dumping /kafka/kafka-logs-broker01/topic_test_demo-0/00000000000000000000.index
        offset: 48 position: 4156
        offset: 96 position: 8332
        offset: 143 position: 12433
        offset: 190 position: 16569
        offset: 237 position: 20705
        offset: 284 position: 24841
        ......
        ```

    3. 查询过程：
    ![image](http://img.blog.csdn.net/20150121164203539)
    要查找绝对offset为7的Message： 
        1. 首先是用二分查找确定它是在哪个LogSegment中，自然是在第一个Segment中。 
        2. 打开这个Segment的index文件，也是用二分查找找到offset小于或者等于指定offset的索引条目中最大的那个offset。自然offset为6的那个索引是我们要找的，通过索引文件我们知道offset为6的Message在数据文件中的位置为9807。 
        3. 打开数据文件，从位置为9807的那个地方开始顺序扫描直到找到offset为7的那条Message。



    